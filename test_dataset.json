[
    {
        "question": "How has generative AI architecture evolved from early probabilistic models to modern transformers?",
        "ground_truth": "Generative AI architecture began with early probabilistic models like Hidden Markov Models (HMMs) and Gaussian Mixed Models (GMMs), which were designed to capture temporal dependencies in sequential data. However, these early models struggled with generalization, leading to the adoption of Restricted Boltzmann Machines (RBMs) and Autoencoders during the deep learning revolution. Variational Autoencoders (VAEs) further improved data generation by encoding inputs into a probabilistic latent space, though they often produced blurry results. In 2014, Generative Adversarial Networks (GANs) introduced a competitive framework between a generator and a discriminator to achieve higher realism. While RNNs and LSTMs were later developed to handle sequential text dependencies, the introduction of the Transformer architecture in 2017 marked a major breakthrough. Modern transformers use self-attention mechanisms to process sequences in parallel and capture long-range dependencies, serving as the foundation for powerful models like GPT-4 and Gemini."
    },
    {
        "question": "How do GANs and VAEs differ in data generation?",
        "ground_truth": "VAEs and GANs utilize distinct architectures for data generation. According to the sources, VAEs employ a probabilistic framework, encoding data into a latent space distribution and decoding samples to generate new points. This process is training-stable but often produces blurry outputs due to reconstruction loss. Conversely, GANs use a competitive minimax game between a generator and a discriminator. While GANs achieve higher realism and sharper images, their adversarial nature makes training unstable and prone to mode collapse. Ultimately, VAEs favor reconstruction stability, while GANs excel in perceptual high-fidelity."
    },
    {
        "question": "Describe the primary training instability issues associated with GANs.",
        "ground_truth": "Training Generative Adversarial Networks (GANs) is infamously unstable due to the adversarial setup where the generator and discriminator compete in a two-player minimax game. This competition often leads to non-convergence, a state where the two networks fail to find a stable equilibrium during the training process. A critical issue is mode collapse, which occurs when the generator produces a limited diversity of outputs, essentially trading variety for high fidelity. Additionally, GANs frequently suffer from vanishing or exploding gradients, which disrupt the backpropagation needed for effective learning. These models are also characterized by an extreme sensitivity to hyperparameters, meaning that even minor setting changes can lead to training failure."
    },
    {
        "question": "Compare training stability across GANs, VAEs, and diffusion models.",
        "ground_truth": "Training stability varies significantly across generative architectures, with Generative Adversarial Networks (GANs) being the most infamously unstable due to the competitive setup between the generator and discriminator. This minimax game often results in vanishing gradients and mode collapse, where the generator produces limited diversity in its outputs. Conversely, Variational Autoencoders (VAEs) are generally much more stable because they utilize a probabilistic framework aimed at maximizing a variational lower bound rather than an adversarial game. However, VAEs can still suffer from posterior collapse, which impacts training stability and often leads to blurry results. Diffusion models are considered very stable and robust compared to their counterparts. Because their training objective is based on variational score matching and iterative denoising rather than competition, they effectively avoid mode collapse and typical convergence issues. Recent advancements like Flow Matching provide even more deterministic and stable formulations for training these models. While diffusion models offer the highest stability and sample quality, they require very high computational costs and significantly more data than VAEs or the faster, single-shot generation processes of GANs."
    }
]