question,answer,contexts,ground_truth,faithfulness,answer_relevancy
How has generative AI architecture evolved from early probabilistic models to modern transformers?,"Based on the provided context, here's an answer to the question:

Generative AI architecture has undergone significant evolution from early probabilistic models to modern transformers. Early models, such as those introduced by Smolensky et al., learned probability distributions over sets of inputs using Harmonium and Restricted Boltzmann Machines (RBMs). These models laid the groundwork for later developments.

The introduction of Deep Belief Networks (DBN) further advanced the field. However, it was not until the deep learning revolution that generative models witnessed significant improvements in performance. The evolution of Generative AI architecture can be summarized as follows:

1. Early probabilistic models: Harmonium and RBMs were introduced to learn probability distributions over sets of inputs.
2. Deep Belief Networks (DBN): Further advanced the field, but it was not until the deep learning revolution that generative models improved significantly.

The modern transformer-based architecture has become a dominant force in Generative AI, enabling the generation of sequential data such as timeseries and speech.","['Table 1: Summary of Reviewed Papers on Generative AI\nPaper YearIncludes\nApplica-\ntions of\nGenAIIncludes\nDown-\nsides of\nGenAIIncludes\nMiti-\ngation\nTech-\nniques\n[18] 2023Yes Yes No\n[19] 2023Yes No No\n[20] 2024Yes No No\n[21] 2023Yes No No\n[22] 2023No Yes No\n[23] 2024No Yes No\n[24] 2024No Yes Yes\n[25] 2023No Yes Yes\nOurs 2025Yes Yes Yes\nareusedtogeneratesequentialdatasuchastimeseriesandspeech[26]. These\nearly models, however, were not very good at generalization [27] and it was\nnot until the deep learning revolution that the generative models witnessed\nsignificant improvements in performance.\nSmolensky et al. [28] introduced Harmonium, which learns the proba-\nbility distribution over a set of inputs. Later, it rose to prominence by the\nname of Restricted Boltzmann Machines (RBMs) after Neural Networks were\npropelled to mainstream use [29] and their application in dimensionality re-\nduction and collaborative filtering [30, 31]. Deep Belief Networks (DBN) and'
 'survey of ai-generated content (aigc): A history of generative ai from\ngan to chatgpt (2023). arXiv:2303.04226 .\nURL https://arxiv.org/abs/2303.04226\n[20] S. Sengar, A. Hasan, S. Kumar, et al., Generative artificial intelligence:\na systematic review and applications, Multimedia Tools and Applica-\ntions (2024). doi:10.1007/s11042-024-20016-1 .\nURL https://doi.org/10.1007/s11042-024-20016-1\n[21] R. Gozalo-Brizuela, E. C. Garrido-Merchán, A survey of generative ai\napplications (2023). arXiv:2306.02781 .\nURL https://arxiv.org/abs/2306.02781\n[22] K. Wach, C. D. Duong, J. Ejdys, R. Kazlauskait˙ e, P. Korzynski,\nG. Mazurek, J. Paliszkiewicz, E. Ziemba, The dark side of generative\nartificial intelligence: A critical analysis of controversies and risks of\nchatgpt, Entrepreneurial Business and Economics Review 11 (2) (2023)\n7–30. doi:10.15678/EBER.2023.110201 .\nURL https://doi.org/10.15678/EBER.2023.110201\n[23] J. Chua, Y. Li, S. Yang, C. Wang, L. Yao, Ai safety in generative ai']","Generative AI architecture began with early probabilistic models like Hidden Markov Models (HMMs) and Gaussian Mixed Models (GMMs), which were designed to capture temporal dependencies in sequential data. However, these early models struggled with generalization, leading to the adoption of Restricted Boltzmann Machines (RBMs) and Autoencoders during the deep learning revolution. Variational Autoencoders (VAEs) further improved data generation by encoding inputs into a probabilistic latent space, though they often produced blurry results. In 2014, Generative Adversarial Networks (GANs) introduced a competitive framework between a generator and a discriminator to achieve higher realism. While RNNs and LSTMs were later developed to handle sequential text dependencies, the introduction of the Transformer architecture in 2017 marked a major breakthrough. Modern transformers use self-attention mechanisms to process sequences in parallel and capture long-range dependencies, serving as the foundation for powerful models like GPT-4 and Gemini.",0.9230769230769231,0.7775832923333081
How do GANs and VAEs differ in data generation?,"According to the context, GANs are capable of generating synthetic data, but their training instability and sensitivity to hyperparameters pose limitations. On the other hand, VAEs can be used for applications like synthetic data generation due to their stability, but they can suffer from posterior collapse affecting training stability and produce blurry outputs when using simple Gaussian decoders and mean-squared error objectives.","['GANs are capable of augmenting the dataset by producing synthetic data,\nhelping with the data requirement [120]. Models like MDGAN developed to\nfix the training instability tend to be computationally expensive [121]. GANs\nare still widely used due to their ability to generate sharp images, but their\ninstability and sensitivity to hyperparameters [122] pose limitations.\nVAEs are generally much more stable to train than GANs, as their ob-\njective is based on maximizing a variational lower bound rather than an\nadversarial game. This stability allows for VAEs to be used for applica-\ntions like synthetic data generation [123] and representation learning [57].\nHowever, VAEs can suffer from posterior collapse affecting training stability\n[124]. They can also sometimes produce blurry outputs when using simple\nGaussian decoders and mean-squared error objectives which limits their ef-\nfectiveness in applications that require high-fidelity data [125]. VAEs can'
 'representations of the data. While PCA is useful for linear dimensionality\nreduction, autoencoders provide a more powerful and versatile approach to\nhandling complex, high-dimensional data. However, the limitation of VAEs\nis that while the data generated by VAEs is quite similar to the original,\nit is not very accurate. This issue was later addressed by the creation of\nGenerative Adversarial Networks (GANs).\nIntroduced in 2014 by Goodfellow et al. [38], GANs contain two net-\nworks, a generator that creates realistic data and a discriminator that tries\nto differentiate between the generated data and the real data. Both the\nmodels are trained using backpropagation. GANs do not need a lot of ap-\nproximations as seen in VAEs because they do not use maximum likelihood\nnor do they require Markov chains as seen in RBMs and its derivatives. How-\never, traditional GANs were limited to generating data from latent samples,\nmeaning it was harder to understand the relationship between the gener-']","VAEs and GANs utilize distinct architectures for data generation. According to the sources, VAEs employ a probabilistic framework, encoding data into a latent space distribution and decoding samples to generate new points. This process is training-stable but often produces blurry outputs due to reconstruction loss. Conversely, GANs use a competitive minimax game between a generator and a discriminator. While GANs achieve higher realism and sharper images, their adversarial nature makes training unstable and prone to mode collapse. Ultimately, VAEs favor reconstruction stability, while GANs excel in perceptual high-fidelity.",0.6363636363636364,0.819349601549173
Describe the primary training instability issues associated with GANs.,"According to the provided context, the primary training instability issues associated with GANs are:

1. Training instability
2. Sensitivity to hyperparameters
3. Mode collapse (catastrophic forgetting)

These issues pose limitations on the use of GANs for applications such as synthetic data generation and representation learning.","['GANs are capable of augmenting the dataset by producing synthetic data,\nhelping with the data requirement [120]. Models like MDGAN developed to\nfix the training instability tend to be computationally expensive [121]. GANs\nare still widely used due to their ability to generate sharp images, but their\ninstability and sensitivity to hyperparameters [122] pose limitations.\nVAEs are generally much more stable to train than GANs, as their ob-\njective is based on maximizing a variational lower bound rather than an\nadversarial game. This stability allows for VAEs to be used for applica-\ntions like synthetic data generation [123] and representation learning [57].\nHowever, VAEs can suffer from posterior collapse affecting training stability\n[124]. They can also sometimes produce blurry outputs when using simple\nGaussian decoders and mean-squared error objectives which limits their ef-\nfectiveness in applications that require high-fidelity data [125]. VAEs can'
 '[142] J. Betker, G. Goh, L. Jing, TimBrooks, J. Wang, L. Li, LongOuyang,\nJuntangZhuang, JoyceLee, YufeiGuo, WesamManassra, PrafullaDhari-\nwal, CaseyChu, YunxinJiao, A. Ramesh, Improving image generation\nwith better captions.\nURL https://api.semanticscholar.org/CorpusID:264403242\n[143] H. Thanh-Tung, T. Tran, Catastrophic forgetting and mode collapse\nin gans, in: 2020 International Joint Conference on Neural Networks\n(IJCNN), 2020, pp. 1–10. doi:10.1109/IJCNN48605.2020.9207181 .\n[144] T. Bhatnagar, S. Kohli, Analyzing the impact of generative adversarial\nnetworks for augmenting imbalanced brain MRI datasets, 2025, pp.\n362–367. doi:10.1201/9781003635680-55 .\n[145] K. C. Dharma, C. T. Morrison, B. Walls, Texture Generation Using\na Graph Generative Adversarial Network and Differentiable Render-\ning, Springer Nature Switzerland, 2023, p. 388–401. doi:10.1007/\n978-3-031-25825-1_28 .\nURL http://dx.doi.org/10.1007/978-3-031-25825-1_28']","Training Generative Adversarial Networks (GANs) is infamously unstable due to the adversarial setup where the generator and discriminator compete in a two-player minimax game. This competition often leads to non-convergence, a state where the two networks fail to find a stable equilibrium during the training process. A critical issue is mode collapse, which occurs when the generator produces a limited diversity of outputs, essentially trading variety for high fidelity. Additionally, GANs frequently suffer from vanishing or exploding gradients, which disrupt the backpropagation needed for effective learning. These models are also characterized by an extreme sensitivity to hyperparameters, meaning that even minor setting changes can lead to training failure.",1.0,0.9768034328380323
"Compare training stability across GANs, VAEs, and diffusion models.","Based on the provided context, here's a comparison of training stability across GANs, VAEs, and diffusion models:

* GANs are known to be unstable to train due to their adversarial nature, which makes them sensitive to hyperparameters.
* VAEs are generally more stable to train than GANs because their objective is based on maximizing a variational lower bound rather than an adversarial game. However, they can suffer from posterior collapse affecting training stability.
* Diffusion models, such as DDPMs, do not suffer the same instability and mode collapse issues that prominent image generation models like GANs suffer from. This is due to their training objective being based on variational score matching rather than adversarial competition.

In summary, VAEs are more stable to train than GANs, but can be affected by posterior collapse. Diffusion models are the most stable among the three, as they avoid the instability and mode collapse issues associated with GANs.","['GANs are capable of augmenting the dataset by producing synthetic data,\nhelping with the data requirement [120]. Models like MDGAN developed to\nfix the training instability tend to be computationally expensive [121]. GANs\nare still widely used due to their ability to generate sharp images, but their\ninstability and sensitivity to hyperparameters [122] pose limitations.\nVAEs are generally much more stable to train than GANs, as their ob-\njective is based on maximizing a variational lower bound rather than an\nadversarial game. This stability allows for VAEs to be used for applica-\ntions like synthetic data generation [123] and representation learning [57].\nHowever, VAEs can suffer from posterior collapse affecting training stability\n[124]. They can also sometimes produce blurry outputs when using simple\nGaussian decoders and mean-squared error objectives which limits their ef-\nfectiveness in applications that require high-fidelity data [125]. VAEs can'
 'Gaussian decoders and mean-squared error objectives which limits their ef-\nfectiveness in applications that require high-fidelity data [125]. VAEs can\nwork effectively with smaller datasets although it can affect the diversity of\noutputs [126].\nDiffusion models such as DDPMs do not suffer the same instability and\nmode collapse issues that prominent image generation models like GANs\nsuffer from. This is due to the fact that their training objective is based\non variational score matching rather than adversarial competition [80]. The\nmain drawback of diffusion models is their high computational cost [127] and\ndata requirement. Generating a single sample typically requires hundreds\nto thousands of iterative denoising steps which makes sampling much slower\nthan the single-shot or few-shot generation of GANs or VAEs [128].\n33']","Training stability varies significantly across generative architectures, with Generative Adversarial Networks (GANs) being the most infamously unstable due to the competitive setup between the generator and discriminator. This minimax game often results in vanishing gradients and mode collapse, where the generator produces limited diversity in its outputs. Conversely, Variational Autoencoders (VAEs) are generally much more stable because they utilize a probabilistic framework aimed at maximizing a variational lower bound rather than an adversarial game. However, VAEs can still suffer from posterior collapse, which impacts training stability and often leads to blurry results. Diffusion models are considered very stable and robust compared to their counterparts. Because their training objective is based on variational score matching and iterative denoising rather than competition, they effectively avoid mode collapse and typical convergence issues. Recent advancements like Flow Matching provide even more deterministic and stable formulations for training these models. While diffusion models offer the highest stability and sample quality, they require very high computational costs and significantly more data than VAEs or the faster, single-shot generation processes of GANs.",1.0,0.8873155869071109
